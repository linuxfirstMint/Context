EverContext — Your AI, Always Up to Date

. プロジェクト概要

EverContext は、コードベースの進化にリアルタイムで追従する差分駆動型 RAG（Retrieval-Augmented Generation）と、ハイブリッド AI オーケストレーションを組み合わせた開発支援プラットフォームです。
クラウド AI の高度な計画力とローカル LLM の安全・低コストな実行力を統合し、開発者が反復的作業やコンテキスト管理から解放され、創造的な課題解決に集中できる環境を提供します。

---

. 解決する課題

コンテキストの陳腐化
従来、LLM はコードベースの更新を手動で反映する必要があり、情報がすぐ古くなる。

API コストとセキュリティのトレードオフ
高性能クラウド AI は高コストかつ機密情報送信リスクあり。ローカル LLM は安全だが高度な推論に弱い。

反復的・定型作業の多さ
ボイラープレート作成、単体テスト、軽微なリファクタリングなどで時間を浪費。

---

. コアコンセプト

思考と実行の分離

司令塔（クラウド AI: Gemini）
曖昧な指示を受け取り、実行可能な計画に分解。

実行部隊（ローカル LLM: Hermes 3 on Ollama）
計画に基づき、安全なローカル環境でコード編集・生成を実施。

差分駆動型 RAG

Git コミットをトリガーに、変更箇所だけをベクトル DB へ反映。

LLM が常に最新コードを参照できる状態を自動維持。

---

. アーキテクチャ構成

. Orchestrator
指示を解析し、司令塔と実行部隊を連携させる中枢。

. MCP (Master Control Program) Server
FastAPI ベースの安全なファイル操作ゲートウェイ。ルート固定・拡張子制限・サイズ上限などを実装。

. RAG Server（フェーズ 3 以降）
コードベースをベクトル化・検索可能にし、計画立案に必要な文脈を供給。

. Gitingest 差分同期ワークフロー
pre-commit フックで差分ファイルのみをスキャン・更新。

---

. 開発フェーズ

. F1: ローカル実行基盤（MVP）
単一指示 → ローカルでファイル生成・編集。

. F2: ハイブリッド連携
曖昧指示 →Gemini 計画 →Hermes 実行。

. F3: RAG 導入
コード参照・修正が可能なコンテキスト認識能力付与。

. F4: 自律性向上
エラー自己修復・ツール拡張（lint/test など）。

---

. 技術スタック

言語: Python 3.11+

クラウド AI: Google Gemini（gemini-cli）

ローカル LLM: Nous Hermes 3（Ollama）

Web フレームワーク: FastAPI

ベクトル DB: ChromaDB / Faiss（予定）

その他: pre-commit, pytest, Poetry, Devcontainer, Taskfile
